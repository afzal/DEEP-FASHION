{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIj47bWFRfdaXajWHE47gb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afzal/DEEP-FASION/blob/main/colorfabrictrends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYLnhHoYGGE7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Fake fashion data: [color_intensity, fabric_type] -> trend_score\n",
        "# Example: [0.8, 0.2] (bright color, cotton) might score 7.5\n",
        "x = np.array([[0.8, 0.2], [0.3, 0.9], [0.5, 0.5], [0.9, 0.1], [0.2, 0.7]], dtype=float)\n",
        "y = np.array([7.5, 4.0, 5.5, 8.0, 3.5], dtype=float)  # Trend scores\n",
        "\n",
        "# Build a 3-layer model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(units=2, input_shape=[2]),  # Input: 2 features\n",
        "    keras.layers.Dense(units=2),                   # Hidden layer\n",
        "    keras.layers.Dense(units=1)                    # Output: 1 trend score\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "# Compile with custom SGD learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x, y, epochs=500, verbose=1)\n",
        "\n",
        "# Print loss history\n",
        "print(\"Loss per epoch:\", history.history['loss'][-5:])  # Last 5 epochs\n",
        "\n",
        "# Predict a trend score for a new item: [bright color, silk]\n",
        "new_item = np.array([[0.9, 0.9]])\n",
        "print(\"Predicted trend score for [0.9, 0.9]:\", model.predict(new_item))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46CGvG49L1h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize\n"
      ],
      "metadata": {
        "id": "VgsGrQs6RW-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Fake fashion data: [color_intensity, fabric_type] -> trend_score\n",
        "# Example: [0.8, 0.2] (bright color, cotton) might score 7.5\n",
        "x = np.array([[0.8, 0.2], [0.3, 0.9], [0.5, 0.5], [0.9, 0.1], [0.2, 0.7]], dtype=float)\n",
        "y = np.array([7.5, 4.0, 5.5, 8.0, 3.5], dtype=float)  # Trend scores\n",
        "y= y/10.0\n",
        "# Build a 3-layer model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(units=2, input_shape=[2]),  # Input: 2 features\n",
        "    keras.layers.Dense(units=2),                   # Hidden layer\n",
        "    keras.layers.Dense(units=1)                    # Output: 1 trend score\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "# Compile with custom SGD learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x, y, epochs=50, verbose=10)\n",
        "\n",
        "# Print loss history\n",
        "print(\"Loss per epoch:\", history.history['loss'][-5:])  # Last 5 epochs\n",
        "\n",
        "# Predict a trend score for a new item: [bright color, silk]\n",
        "new_item = np.array([[0.9, 0.9]])\n",
        "print(\"new_item:\", new_item)\n",
        "print(\"Predicted trend score for [0.9, 0.9]:\", model.predict(new_item)[0][0] * 10.0)"
      ],
      "metadata": {
        "id": "1rauQ_CCOBet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNcG5uUgTlXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shape"
      ],
      "metadata": {
        "id": "bKffF2HMSRel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of new_item:\", new_item.shape)  # Add this line"
      ],
      "metadata": {
        "id": "3h2VfgeuSTN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1, 2):\n",
        "        1: Number of samples (you’re predicting for 1 item).\n",
        "        2: Number of features per sample (color intensity and fabric type).\n",
        "\n"
      ],
      "metadata": {
        "id": "BUJ4QPU8SaNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of x:\", x.shape)  # Should be (5, 2)\n",
        "print(\"Shape of y:\", y.shape)"
      ],
      "metadata": {
        "id": "A-rgWzLcSbDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Fake fashion data: [color_intensity, fabric_type] -> trend_score\n",
        "# Example: [0.8, 0.2] (bright color, cotton) might score 7.5\n",
        "x = np.array([[0.8, 0.2], [0.3, 0.9], [0.5, 0.5], [0.9, 0.1], [0.2, 0.7]], dtype=float)\n",
        "y = np.array([7.5, 4.0, 5.5, 8.0, 3.5], dtype=float)  # Trend scores\n",
        "y= y/10.0\n",
        "# Build a 3-layer model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(units=2, input_shape=[2], activation='relu'),  # Input: 2 features\n",
        "    keras.layers.Dense(units=2, activation='relu'),                   # Hidden layer\n",
        "    keras.layers.Dense(units=1)                    # Output: 1 trend score\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "# Compile with custom SGD learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x, y, epochs=50, verbose=10)\n",
        "\n",
        "# Print loss history\n",
        "print(\"Loss per epoch:\", history.history['loss'][-5:])  # Last 5 epochs\n",
        "\n",
        "# Predict a trend score for a new item: [bright color, silk]\n",
        "new_item = np.array([[0.9, 0.9]])\n",
        "print(\"new_item:\", new_item)\n",
        "print(\"Predicted trend score for [0.9, 0.9]:\", model.predict(new_item)[0][0] * 10.0)"
      ],
      "metadata": {
        "id": "QK5gucfCTmd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of new_item:\", model.predict(new_item).shape)"
      ],
      "metadata": {
        "id": "7F3KG9nGU5NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here output_dim Appears in Your Model\n",
        "\n",
        "In Keras, the units parameter in a Dense layer defines the output_dim of that layer. Let’s look at each layer in your model:\n",
        "1. Layer 1: Dense(units=2, input_shape=[2], activation='relu')\n",
        "\n",
        "    Input Shape: [2] (color intensity, fabric type).\n",
        "    Output Dim (units): 2 — this layer outputs 2 values for each input example.\n",
        "    What It Means:\n",
        "        For an input like [0.9, 0.9], this layer computes 2 numbers (e.g., [1.2, 0.5] after relu).\n",
        "        Each of the 2 neurons in this layer produces one value, so the output_dim is 2.\n",
        "    Shape of Output: (n_samples, 2) — for 1 sample, it’s (1, 2).\n",
        "\n",
        "2. Layer 2: Dense(units=2, activation='relu')\n",
        "\n",
        "    Input Shape: [2] (from the previous layer’s output).\n",
        "    Output Dim (units): 2 — this layer also outputs 2 values.\n",
        "    What It Means:\n",
        "        Takes the 2 values from Layer 1 (e.g., [1.2, 0.5]), processes them, and outputs 2 new values (e.g., [0.8, 0.3]).\n",
        "        output_dim is still 2.\n",
        "    Shape of Output: (n_samples, 2) — still (1, 2) for 1 sample.\n",
        "\n",
        "3. Layer 3: Dense(units=1)\n",
        "\n",
        "    Input Shape: [2] (from Layer 2).\n",
        "    Output Dim (units): 1 — this layer outputs 1 value.\n",
        "    What It Means:\n",
        "        Takes the 2 values from Layer 2 (e.g., [0.8, 0.3]), processes them, and outputs 1 value (e.g., 0.78).\n",
        "        This is the final trend score (in the normalized 0-1 range).\n",
        "        output_dim is 1.\n",
        "    Shape of Output: (n_samples, 1) — for 1 sample, it’s (1, 1).\n",
        "\n",
        "each layer: (n_samples, Output Dim )\n",
        "\n",
        "------\n",
        "new_item has shape (1, 2) (1 sample, 2 features).\n",
        "\n",
        "\n",
        "\n",
        "Connecting to model.predict(new_item)[0][0] * 10.0\n",
        "\n",
        "Let’s see how output_dim relates to the prediction line you asked about earlier:\n",
        "\n",
        "    model.predict(new_item):"
      ],
      "metadata": {
        "id": "uQYlHaQ_YCK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "each layer: (n_samples, Output Dim )\n",
        "\n",
        "new_item has shape (1, 2) (1 sample, 2 features).\n"
      ],
      "metadata": {
        "id": "wkvn600BazUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict for 3 items\n",
        "new_items = np.array([[0.9, 0.9], [0.5, 0.5], [0.2, 0.3]])  # 3 items\n",
        "print(\"new_items Shape:\", new_items.shape)\n"
      ],
      "metadata": {
        "id": "BCrJzWWZYDbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(new_items)\n",
        "print(\"Prediction:\", prediction)\n",
        "print(\"Prediction Shape:\", prediction.shape)\n",
        "print(\"Item 1 score:\", prediction[0][0] * 10.0)\n",
        "print(\"Item 2 score:\", prediction[1][0] * 10.0)\n",
        "print(\"Item 3 score:\", prediction[2][0] * 10.0)\n",
        "# Try [2][3]\n",
        "try:\n",
        "    print(\"Trying [2][3]:\", prediction[2][3])\n",
        "except IndexError as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "id": "gHTA__35bOTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle"
      ],
      "metadata": {
        "id": "UK901QxHeBuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "0yBJ1W5xi5IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "RYXj98yLjJJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "9PlRBAEjjtHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ~/.kaggle/"
      ],
      "metadata": {
        "id": "DAMMUNZ8kjdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle --version"
      ],
      "metadata": {
        "id": "9bxTB5nSknn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-dataset --unzip\n"
      ],
      "metadata": {
        "id": "m2wjQdhXmWat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "oRdPX7aJL4l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline(\"text-generation\", model=\"gpt2\")"
      ],
      "metadata": {
        "id": "izsI0NYsMM9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The cat sat on\""
      ],
      "metadata": {
        "id": "1wxc5QseMltu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model(prompt, max_length=by 20, num_return_sequences=1)"
      ],
      "metadata": {
        "id": "KCcfkvMyM3xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "Kgz68dMaNHYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the model\n",
        "model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Give it a starting point\n",
        "prompt = \"I need life inspiration\"\n",
        "\n",
        "# Generate text\n",
        "result = model(prompt, max_length=20, num_return_sequences=1)\n",
        "\n",
        "# Show the result\n",
        "print(result[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "144tRdH3OTrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the model\n",
        "model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Set the prompt\n",
        "prompt = \"The robot explored the\"\n",
        "\n",
        "# Generate text with options\n",
        "result = model(prompt, max_length=20, temperature=1.2, top_k=500, num_return_sequences=1)\n",
        "\n",
        "# Print the result\n",
        "print(result[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "VOEzG4FTPf57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}